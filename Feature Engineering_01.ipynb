{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8076161c-8e4c-4635-9a17-ead804338ba7",
   "metadata": {},
   "source": [
    "# Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bdf587-b802-443b-9ea2-d5727d274523",
   "metadata": {},
   "source": [
    "Missing values are the values that are not present in a dataset for a particular observation or instance. These missing values may occur due to various reasons such as data corruption, data entry errors, data processing errors, or incomplete data. Missing values can be represented in different forms such as NaN, null, NA, or simply left as an empty cell.\n",
    "\n",
    "Handling missing values is essential because it can affect the quality and accuracy of the analysis and prediction models that are built from the dataset. Missing values can lead to biased or inaccurate estimates of statistical measures such as mean, variance, correlation, and regression coefficients, as well as result in incorrect predictions from machine learning models. Moreover, some algorithms cannot handle missing values and may crash or produce invalid results if missing values are present in the dataset.\n",
    "\n",
    "Some of the algorithms that are not affected by missing values include:\n",
    "\n",
    "1. Tree-based algorithms such as Decision Trees, Random Forest, and Gradient Boosting Machines, which can handle missing values by branching the tree at each node based on the available features and observations.\n",
    "\n",
    "2. Support Vector Machines (SVM), which can ignore missing values during model training and prediction.\n",
    "\n",
    "3. K-Nearest Neighbors (KNN), which can handle missing values by imputing the missing values with the average or median of the neighboring observations.\n",
    "\n",
    "4. Naive Bayes, which can handle missing values by ignoring the missing values and computing the conditional probabilities based on the available features.\n",
    "\n",
    "However, it is still recommended to handle missing values before applying any algorithm to the dataset, as it can improve the performance and accuracy of the algorithm. Common techniques for handling missing values include imputation methods, such as mean imputation, median imputation, and mode imputation, or deletion methods, such as listwise deletion, pairwise deletion, or mean substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e933ef-9901-4217-81b4-0396b2515f90",
   "metadata": {},
   "source": [
    "# Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20b433-a128-48e5-9d31-f29ea05c4d55",
   "metadata": {},
   "source": [
    "There are several techniques to handle missing data. Some of them are:\n",
    "\n",
    "Deletion Technique:\n",
    "\n",
    "a. Listwise Deletion\n",
    "\n",
    "b. Pairwise Deletion\n",
    "\n",
    "Imputation Technique:\n",
    "\n",
    "a. Mean/ Median/ Mode Imputation\n",
    "\n",
    "b. Regression Imputation\n",
    "\n",
    "c. K-Nearest Neighbors Imputation\n",
    "\n",
    "d. Multiple Imputation\n",
    "\n",
    "e. Hot-Deck Imputation\n",
    "\n",
    "Here is an example of how to implement each of these techniques in Python:\n",
    "\n",
    "1. Deletion Technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0b2fd95-0eba-4949-98bf-21237b6254b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>accepted_payments</th>\n",
       "      <th>alternate_name</th>\n",
       "      <th>application_process</th>\n",
       "      <th>audience</th>\n",
       "      <th>description</th>\n",
       "      <th>eligibility</th>\n",
       "      <th>email</th>\n",
       "      <th>...</th>\n",
       "      <th>interpretation_services</th>\n",
       "      <th>keywords</th>\n",
       "      <th>languages</th>\n",
       "      <th>name</th>\n",
       "      <th>required_documents</th>\n",
       "      <th>service_areas</th>\n",
       "      <th>status</th>\n",
       "      <th>wait_time</th>\n",
       "      <th>website</th>\n",
       "      <th>taxonomy_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Walk in or apply by phone.</td>\n",
       "      <td>Older adults age 55 or over, ethnic minorities...</td>\n",
       "      <td>A walk-in center for older adults that provide...</td>\n",
       "      <td>Age 55 or over for most programs, age 60 or ov...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ADULT PROTECTION AND CARE SERVICES, Meal Sites...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair Oaks Adult Activity Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Colma</td>\n",
       "      <td>active</td>\n",
       "      <td>No wait.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apply by phone for an appointment.</td>\n",
       "      <td>Residents of San Mateo County age 55 or over</td>\n",
       "      <td>Provides training and job placement to eligibl...</td>\n",
       "      <td>Age 55 or over, county resident and willing an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMPLOYMENT/TRAINING SERVICES, Job Development,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Second Career Employment Program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Mateo County</td>\n",
       "      <td>active</td>\n",
       "      <td>Varies.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone for information (403-4300 Ext. 4322).</td>\n",
       "      <td>Older adults age 55 or over who can benefit fr...</td>\n",
       "      <td>Offers supportive counseling services to San M...</td>\n",
       "      <td>Resident of San Mateo County age 55 or over</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geriatric Counseling, Older Adults, Gay, Lesbi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Senior Peer Counseling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Mateo County</td>\n",
       "      <td>active</td>\n",
       "      <td>Varies.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apply by phone.</td>\n",
       "      <td>Parents, children, families with problems of c...</td>\n",
       "      <td>Provides supervised visitation services and a ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INDIVIDUAL AND FAMILY DEVELOPMENT SERVICES, Gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Visitation Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Mateo County</td>\n",
       "      <td>active</td>\n",
       "      <td>No wait.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phone for information.</td>\n",
       "      <td>Low-income working families with children tran...</td>\n",
       "      <td>Provides fixed 8% short term loans to eligible...</td>\n",
       "      <td>Eligibility: Low-income family with legal cust...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COMMUNITY SERVICES, Speakers, Automobile Loans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Economic Self-Sufficiency Program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>San Mateo County</td>\n",
       "      <td>active</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  location_id  program_id accepted_payments alternate_name  \\\n",
       "0   1            1         NaN               NaN            NaN   \n",
       "1   2            2         NaN               NaN            NaN   \n",
       "2   3            3         NaN               NaN            NaN   \n",
       "3   4            4         NaN               NaN            NaN   \n",
       "4   5            5         NaN               NaN            NaN   \n",
       "\n",
       "                           application_process  \\\n",
       "0                   Walk in or apply by phone.   \n",
       "1           Apply by phone for an appointment.   \n",
       "2  Phone for information (403-4300 Ext. 4322).   \n",
       "3                              Apply by phone.   \n",
       "4                       Phone for information.   \n",
       "\n",
       "                                            audience  \\\n",
       "0  Older adults age 55 or over, ethnic minorities...   \n",
       "1       Residents of San Mateo County age 55 or over   \n",
       "2  Older adults age 55 or over who can benefit fr...   \n",
       "3  Parents, children, families with problems of c...   \n",
       "4  Low-income working families with children tran...   \n",
       "\n",
       "                                         description  \\\n",
       "0  A walk-in center for older adults that provide...   \n",
       "1  Provides training and job placement to eligibl...   \n",
       "2  Offers supportive counseling services to San M...   \n",
       "3  Provides supervised visitation services and a ...   \n",
       "4  Provides fixed 8% short term loans to eligible...   \n",
       "\n",
       "                                         eligibility email  ...  \\\n",
       "0  Age 55 or over for most programs, age 60 or ov...   NaN  ...   \n",
       "1  Age 55 or over, county resident and willing an...   NaN  ...   \n",
       "2        Resident of San Mateo County age 55 or over   NaN  ...   \n",
       "3                                               None   NaN  ...   \n",
       "4  Eligibility: Low-income family with legal cust...   NaN  ...   \n",
       "\n",
       "  interpretation_services                                           keywords  \\\n",
       "0                     NaN  ADULT PROTECTION AND CARE SERVICES, Meal Sites...   \n",
       "1                     NaN  EMPLOYMENT/TRAINING SERVICES, Job Development,...   \n",
       "2                     NaN  Geriatric Counseling, Older Adults, Gay, Lesbi...   \n",
       "3                     NaN  INDIVIDUAL AND FAMILY DEVELOPMENT SERVICES, Gr...   \n",
       "4                     NaN     COMMUNITY SERVICES, Speakers, Automobile Loans   \n",
       "\n",
       "  languages                               name required_documents  \\\n",
       "0       NaN    Fair Oaks Adult Activity Center                NaN   \n",
       "1       NaN   Second Career Employment Program                NaN   \n",
       "2       NaN             Senior Peer Counseling                NaN   \n",
       "3       NaN           Family Visitation Center                NaN   \n",
       "4       NaN  Economic Self-Sufficiency Program                NaN   \n",
       "\n",
       "      service_areas  status wait_time website taxonomy_ids  \n",
       "0             Colma  active  No wait.     NaN          NaN  \n",
       "1  San Mateo County  active   Varies.     NaN          NaN  \n",
       "2  San Mateo County  active   Varies.     NaN          NaN  \n",
       "3  San Mateo County  active  No wait.     NaN          NaN  \n",
       "4  San Mateo County  active       NaN     NaN          NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Listwise Deletion:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d296808-2108-4cb8-946e-5a08184db249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listwise Deletion\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60634cef-4127-44bf-8018-e7411a81cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       0 non-null      int64  \n",
      " 1   location_id              0 non-null      int64  \n",
      " 2   program_id               0 non-null      float64\n",
      " 3   accepted_payments        0 non-null      object \n",
      " 4   alternate_name           0 non-null      object \n",
      " 5   application_process      0 non-null      object \n",
      " 6   audience                 0 non-null      object \n",
      " 7   description              0 non-null      object \n",
      " 8   eligibility              0 non-null      object \n",
      " 9   email                    0 non-null      object \n",
      " 10  fees                     0 non-null      object \n",
      " 11  funding_sources          0 non-null      object \n",
      " 12  interpretation_services  0 non-null      object \n",
      " 13  keywords                 0 non-null      object \n",
      " 14  languages                0 non-null      object \n",
      " 15  name                     0 non-null      object \n",
      " 16  required_documents       0 non-null      object \n",
      " 17  service_areas            0 non-null      object \n",
      " 18  status                   0 non-null      object \n",
      " 19  wait_time                0 non-null      object \n",
      " 20  website                  0 non-null      object \n",
      " 21  taxonomy_ids             0 non-null      object \n",
      "dtypes: float64(1), int64(2), object(19)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab89f4f-9de7-4e05-a629-473fb7edeec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>program_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  location_id  program_id\n",
       "count  0.0          0.0         0.0\n",
       "mean   NaN          NaN         NaN\n",
       "std    NaN          NaN         NaN\n",
       "min    NaN          NaN         NaN\n",
       "25%    NaN          NaN         NaN\n",
       "50%    NaN          NaN         NaN\n",
       "75%    NaN          NaN         NaN\n",
       "max    NaN          NaN         NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e0edfc3-a655-49ec-b132-b3750f622449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0.0\n",
       "location_id                0.0\n",
       "program_id                 0.0\n",
       "accepted_payments          0.0\n",
       "alternate_name             0.0\n",
       "application_process        0.0\n",
       "audience                   0.0\n",
       "description                0.0\n",
       "eligibility                0.0\n",
       "email                      0.0\n",
       "fees                       0.0\n",
       "funding_sources            0.0\n",
       "interpretation_services    0.0\n",
       "keywords                   0.0\n",
       "languages                  0.0\n",
       "name                       0.0\n",
       "required_documents         0.0\n",
       "service_areas              0.0\n",
       "status                     0.0\n",
       "wait_time                  0.0\n",
       "website                    0.0\n",
       "taxonomy_ids               0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49016975-84f7-4e84-bc4c-4fc3839d72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Pairwise Deletion:\n",
    "\n",
    "data.dropna(subset=['languages', 'required_documents'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e9b88-578c-4775-957c-12aa7cb8aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation Technique:\n",
    "# a. Mean/ Median/ Mode Imputation:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "\n",
    "# Mean Imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data['name'] = imputer.fit_transform(data[['service_areas']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b21c294-954f-4319-bade-4ad4bc13b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Regression Imputation:\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "\n",
    "# Regression Imputation\n",
    "imputer = IterativeImputer()\n",
    "data['column_name'] = imputer.fit_transform(data[['column_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943e7943-8da9-497a-a506-1d0dfa261c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. K-Nearest Neighbors Imputation:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "\n",
    "# KNN Imputation\n",
    "imputer = KNNImputer()\n",
    "data['column_name'] = imputer.fit_transform(data[['column_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097b09-5546-4902-922a-f210ebe3cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Multiple Imputation:\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "\n",
    "# Multiple Imputation\n",
    "imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "data['column_name'] = imputer.fit_transform(data[['column_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831e3c5-49c1-4cc9-ba9e-215f9f329be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Hot-Deck Imputation:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('services.csv')\n",
    "\n",
    "# Hot-Deck Imputation\n",
    "data['column_name'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b392f11-2386-4cf3-8164-c673d34be5a7",
   "metadata": {},
   "source": [
    "# Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a558174-4703-47ac-b425-b297916c048d",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation where the number of observations in one class is significantly higher or lower than the other classes in a binary or multi-class classification problem. For example, in a medical dataset, the number of healthy patients may be much higher than the number of patients with a disease.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to biased model performance. The classifier tends to favor the majority class and ignores the minority class, resulting in poor classification results for the minority class. In such cases, the accuracy metric can be misleading as it may report high accuracy despite poor performance on the minority class.\n",
    "\n",
    "For example, suppose we have a dataset with two classes, where 90% of the observations belong to class A and 10% to class B. If we train a model on this dataset without handling the imbalance, it will likely predict all new observations as belonging to class A, as it achieves a high accuracy of 90%. However, the model's ability to predict the minority class will be very poor, leading to low recall, precision, and F1-score.\n",
    "\n",
    "Thus, handling imbalanced data is crucial to train a model that can perform well on both majority and minority classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5e7bd-e8cd-4fe0-92ce-8e8bfa279239",
   "metadata": {},
   "source": [
    "# Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea6497-7b9b-40b5-b289-2fd3685c2904",
   "metadata": {},
   "source": [
    "Up-sampling and down-sampling are techniques used to handle imbalanced data in machine learning.\n",
    "\n",
    "Up-sampling is a technique in which the minority class is artificially increased by adding more samples to it. This can be done by replicating existing samples or generating new synthetic samples using techniques such as SMOTE (Synthetic Minority Over-sampling Technique). Up-sampling is typically used when the number of samples in the minority class is significantly lower than the majority class.\n",
    "\n",
    "For example, suppose you have a dataset of customer churn, and only 5% of customers churned while 95% did not. In this case, up-sampling can be used to balance the dataset by artificially increasing the number of churned customers to match the non-churned customers.\n",
    "\n",
    "Down-sampling, on the other hand, is a technique in which the majority class is reduced by randomly removing samples from it. This is typically used when the number of samples in the majority class is significantly higher than the minority class.\n",
    "\n",
    "For example, suppose you have a dataset of credit card fraud detection, and only 1% of transactions are fraudulent while 99% are not. In this case, down-sampling can be used to balance the dataset by randomly removing some of the non-fraudulent transactions to match the number of fraudulent transactions.\n",
    "\n",
    "Both up-sampling and down-sampling have their pros and cons, and the choice of technique depends on the specific problem and dataset at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f34b5-8857-434b-92a1-ccc1df8bcf95",
   "metadata": {},
   "source": [
    "# Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44ff55-710c-4275-ac3f-4138b80256f0",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used to artificially increase the size of a dataset by creating new data points based on existing ones. It is a common technique used in machine learning to improve model performance, especially when the original dataset is small or imbalanced.\n",
    "\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation technique used to address the issue of imbalanced datasets. It involves generating new synthetic examples of the minority class by interpolating between existing minority class samples. SMOTE works by randomly selecting one sample from the minority class, selecting one of its k nearest neighbors, and then generating a new synthetic sample at a randomly chosen point between the two selected samples. This process is repeated until the desired level of oversampling is achieved.\n",
    "\n",
    "For example, let's say we have a dataset of credit card transactions, and only 2% of the transactions are fraudulent. In this case, the dataset is imbalanced, and we can use SMOTE to generate synthetic examples of fraudulent transactions. By using SMOTE, we can create new synthetic examples of fraudulent transactions that are similar to the existing ones, but with slight variations in the data. This can help to balance the dataset and improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d1715-284d-4a2c-bae3-6e340a575449",
   "metadata": {},
   "source": [
    "# Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840b2754-8f37-4646-aa6b-5de488e109bb",
   "metadata": {},
   "source": [
    "Outliers are observations in a dataset that are significantly different from other observations in the same dataset. Outliers can be caused by measurement errors, data entry errors, or rare events.\n",
    "\n",
    "It is essential to handle outliers because they can significantly impact the statistical analysis and modeling of the data. Outliers can skew the results of the analysis, leading to incorrect conclusions, and they can also affect the accuracy and performance of machine learning models.\n",
    "\n",
    "There are different techniques to handle outliers, such as:\n",
    "\n",
    "1. Removing outliers: Outliers can be removed from the dataset if they are due to measurement errors or data entry errors. However, if the outliers represent rare events or important information, removing them can result in loss of valuable insights.\n",
    "\n",
    "2. Replacing outliers: Outliers can be replaced with more appropriate values, such as the mean or median of the dataset. However, this technique can also lead to loss of valuable information if the outliers represent important data.\n",
    "\n",
    "3. Transforming data: The data can be transformed using techniques such as log transformation or Box-Cox transformation to make it more normally distributed and reduce the impact of outliers.\n",
    "\n",
    "4. Using robust statistical models: Robust statistical models, such as the Median Absolute Deviation (MAD) or the Huber Loss function, can be used to reduce the impact of outliers on the analysis.\n",
    "\n",
    "5. Using anomaly detection techniques: Anomaly detection techniques can be used to identify and remove or handle outliers in the dataset.\n",
    "\n",
    "One of the popular techniques for handling imbalanced datasets, SMOTE (Synthetic Minority Over-sampling Technique) is also used for handling outliers. SMOTE generates synthetic samples of the minority class by creating synthetic observations that are combinations of the existing minority class observations. This technique can help balance the class distribution and improve the performance of machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d593ac4-b51c-423e-bc37-5fd9550a9a0f",
   "metadata": {},
   "source": [
    "# Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cd68a-0844-4d29-ae9f-e97700ad657d",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to handle missing data in a dataset, some of which are:\n",
    "\n",
    "1. Deletion: This technique involves deleting the rows or columns with missing values from the dataset. However, this method can lead to a loss of valuable information.\n",
    "\n",
    "2. Imputation: This technique involves filling in the missing values with estimated values. There are several methods for imputation, including mean imputation, median imputation, mode imputation, and regression imputation.\n",
    "\n",
    "3. K-nearest neighbors (KNN) imputation: This technique involves estimating the missing values by using the values of the K-nearest neighbors.\n",
    "\n",
    "4. Multiple imputation: This technique involves generating multiple imputed datasets and then analyzing the results from each dataset to obtain an overall estimate.\n",
    "\n",
    "Here is an example in Python using the mean imputation technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15065cb6-39d6-45de-8a5e-762bcd6dfac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a sample dataset with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, np.nan, 4, 5], 'B': [6, 7, 8, np.nan, 10]})\n",
    "\n",
    "# replace missing values with mean value of the column\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce2ed5-b705-434e-9d5f-db93c5020942",
   "metadata": {},
   "source": [
    "# Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc137f-d932-4ce2-b60c-0b3b8baa3395",
   "metadata": {},
   "source": [
    "There are several strategies that can be used to determine if missing data is missing at random or if there is a pattern to the missing data:\n",
    "\n",
    "1. Missing Completely at Random (MCAR) test: In this test, missingness is assumed to be completely random and is not related to any other variable in the dataset. One way to test this assumption is to compare the missingness of a variable to another variable that is completely observed. This can be done using a t-test or chi-square test.\n",
    "\n",
    "2. Missing at Random (MAR) test: In this test, missingness is related to other variables in the dataset but not to the missing data itself. One way to test this assumption is to create a missingness indicator variable and include it in the analysis. If the indicator variable is not significant, then missingness is assumed to be at random.\n",
    "\n",
    "3. Missing Not at Random (MNAR) test: In this test, missingness is related to the missing data itself. This is the most difficult scenario to test for because the missing data cannot be observed. One way to test this assumption is to use sensitivity analysis or imputation methods.\n",
    "\n",
    "Overall, it is important to identify the pattern of missing data before choosing an appropriate method for handling it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254ddd3d-15b2-451a-b5b2-32196ef13e18",
   "metadata": {},
   "source": [
    "# Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7a251-a893-4d76-aa2a-66782ecb044f",
   "metadata": {},
   "source": [
    "When dealing with an imbalanced dataset, traditional evaluation metrics such as accuracy may not be sufficient as they can be misleading. Here are some strategies that can be used to evaluate the performance of a machine learning model on an imbalanced dataset:\n",
    "\n",
    "1. Confusion matrix: A confusion matrix is a table that is used to evaluate the performance of a classification model. It provides information about the true positive, true negative, false positive, and false negative rates. This information can be used to calculate metrics such as precision, recall, and F1 score.\n",
    "\n",
    "2. ROC curve: The Receiver Operating Characteristic (ROC) curve is a plot that shows the performance of a binary classifier system as its discrimination threshold is varied. It plots the true positive rate (sensitivity) against the false positive rate (1 - specificity) for various threshold values.\n",
    "\n",
    "3. Precision-Recall curve: Precision-Recall (PR) curve is another method to evaluate the performance of binary classifiers. It plots precision (positive predictive value) against recall (sensitivity) for various threshold values.\n",
    "\n",
    "4. Stratified sampling: This technique can be used to ensure that the data is sampled in a way that is representative of the distribution of the target variable. In this method, the dataset is split into training and testing sets in such a way that the proportion of the target variable is maintained in both sets.\n",
    "\n",
    "5. Resampling techniques: Up-sampling and down-sampling techniques can be used to balance the dataset. Up-sampling involves duplicating the minority class samples while down-sampling involves removing samples from the majority class.\n",
    "\n",
    "6. Cost-sensitive learning: In cost-sensitive learning, different costs are assigned to different types of classification errors. For example, a false negative may have a higher cost than a false positive. The model is then optimized based on these costs.\n",
    "\n",
    "7. Ensemble methods: Ensemble methods such as bagging, boosting, and stacking can be used to improve the performance of the model on imbalanced datasets.\n",
    "\n",
    "It is important to note that the choice of evaluation strategy will depend on the specific problem and the goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce69ddd-7aaa-479d-a76b-5e21d94659a3",
   "metadata": {},
   "source": [
    "# Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e32094-e85d-42e7-9f11-2a4289a93997",
   "metadata": {},
   "source": [
    "If we want to balance an imbalanced dataset where the majority class is overrepresented, we can use down-sampling techniques. Here are some methods to down-sample the majority class:\n",
    "\n",
    "1. Random Under-Sampling: In this technique, we randomly select a subset of observations from the majority class to match the size of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343573b8-b574-46aa-9a32-10868b8bd095",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[1;32m      3\u001b[0m rus \u001b[38;5;241m=\u001b[39m RandomUnderSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m rus\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c34af8-068a-4fcb-8bfd-6c5e77699a54",
   "metadata": {},
   "source": [
    "2. Tomek Links: In this technique, we remove the observations of the majority class that are close to the minority class observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f80e7cb-0479-49de-be5a-b4bc13d2a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_resampled, y_resampled = tl.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482a7e96-8970-40b2-a326-70c83c768970",
   "metadata": {},
   "source": [
    "3. Cluster Centroids: In this technique, we create centroids based on the majority class observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acadf98-8c62-4f5b-b803-7eed710ed8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids()\n",
    "X_resampled, y_resampled = cc.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6460144-5848-4c73-9731-eed42f548481",
   "metadata": {},
   "source": [
    "4. NearMiss: In this technique, we select the majority class observations that are closest to the minority class observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b75f1-88bc-454e-bc25-4b9a7d0ffc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "nm = NearMiss()\n",
    "X_resampled, y_resampled = nm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a94c15-b9c8-435c-bf51-7be4f4075c53",
   "metadata": {},
   "source": [
    "# Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbcdedd-1f3a-43ce-9806-302deaf029bf",
   "metadata": {},
   "source": [
    "When dealing with imbalanced datasets with a low percentage of occurrences, we can use up-sampling techniques to balance the dataset. Some of the techniques are:\n",
    "\n",
    "1. Random oversampling: This method involves randomly duplicating the minority class samples to balance the dataset. This method is simple but can lead to overfitting.\n",
    "\n",
    "2. SMOTE (Synthetic Minority Over-sampling Technique): SMOTE creates synthetic samples of the minority class by creating new samples that are combinations of the minority class samples that already exist. The synthetic samples are generated by selecting one or more nearest neighbors of a sample and generating a new sample that is a combination of the selected sample and the neighbors.\n",
    "\n",
    "3. ADASYN (Adaptive Synthetic Sampling): ADASYN is similar to SMOTE, but it generates more synthetic samples for the minority class samples that are harder to learn. ADASYN assigns weights to the samples based on the number of samples in the class and the distance to the neighboring samples.\n",
    "\n",
    "4. Random undersampling: This method involves randomly removing samples from the majority class to balance the dataset. However, this method can result in the loss of useful information.\n",
    "\n",
    "Here is an example of using SMOTE to up-sample the minority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09774d7-1292-413e-b0d6-c8a47a2ae3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X and y are the feature matrix and target vector, respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
